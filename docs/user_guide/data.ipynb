{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654a7e7d-0d37-48dd-9738-4c20c510ad8e",
   "metadata": {},
   "source": [
    "# Working with different datasets\n",
    "`huracanpy` can load track data from various formats. For testing, there are a few\n",
    "example files embedded in `huracanpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7277cf91-e086-4062-9ac6-0798148abbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import huracanpy\n",
    "\n",
    "print(huracanpy.example_csv_file.split(\"/\")[-1])\n",
    "print(huracanpy.example_TRACK_netcdf_file.split(\"/\")[-1])\n",
    "print(huracanpy.example_TRACK_file.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef691b1f-9fb4-405c-a650-6538f21c75b8",
   "metadata": {},
   "source": [
    "## CSV\n",
    "\n",
    "A CSV is a useful way of storing track data. If you tracks are stored in csv (including\n",
    "if they were outputed from TempestExtremes' StitchNodes), you can specify the\n",
    "`source=\"csv\"` argument, or, if your filename ends with *csv*, it will be detected\n",
    "automatically.\n",
    "\n",
    "`huracanpy.load` will read most of the CSV file as it is to output as an\n",
    "`xarray.Dataset`. There can be a few extra modifications\n",
    "to make sure the output has the variables `track_id`, `time`, `lon`, and `lat`.\n",
    "For example, in the file used here, the time variable is constructed from\n",
    "`year`, `month`, `day`, and `hour`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bf511e-dc63-4ca1-95fb-e2c1e5116d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "huracanpy.load(huracanpy.example_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4ed4e3-7983-42e1-a345-60bdea8418db",
   "metadata": {},
   "source": [
    "## NetCDF\n",
    "\n",
    "Similar to CSV, NetCDF data can largely be loaded as is. NetCDF has the disadvantage of\n",
    "not being readable like a CSV, but the advantage that it can better store metadata about\n",
    "variables.\n",
    "\n",
    "The only assumption about the NetCDF file, is that it is using the CF convention\n",
    "\n",
    "http://cfconventions.org/Data/cf-conventions/cf-conventions-1.11/cf-conventions.html#_contiguous_ragged_array_representation_of_trajectories\n",
    "\n",
    "This allows the load function to identify the TRACK_ID and extend it along the data\n",
    "dimension. Like loading CSV data, some variables are renamed. In the example the positions\n",
    "are `longitude` and `latitude` in the netCDF file, but are renamed to `lon` and `lat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba97a62-dc2f-4d2c-838b-555c846890cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "huracanpy.load(huracanpy.example_TRACK_netcdf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aeaf8d-3653-49ee-99bb-8b9834106fe8",
   "metadata": {},
   "source": [
    "## TRACK\n",
    "\n",
    "Note that TRACK files don't contain the variable names, instead they are usually\n",
    "described in the filename. Currently `huracanpy.load` doesn't try to infer the variable\n",
    "names from the filename. Instead, any extra variables will be named feature_n, where\n",
    "n is between 0 and number of variables minus 1. TRACK also associates extra coordinates\n",
    "with some of these features, these will be loaded as feature_n_longitude and\n",
    "feature_n_latitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebad373-64d9-43cb-ad5a-ed758d71ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "huracanpy.load(huracanpy.example_TRACK_file, source=\"TRACK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10edab87-a4a6-4201-896d-99a5ffacec7e",
   "metadata": {},
   "source": [
    "If you want to load the variables by name, then pass a list of variable names to\n",
    "`huracanpy.load`. The associated longitudes/latitudes are associated to the respective\n",
    "feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9770ec-6617-46ca-b6b7-3ec7953d0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_names = [\n",
    "    *[f\"vorticity_{n}hPa\" for n in [850, 700, 600, 500, 400, 300, 200]],\n",
    "    \"mslp\",\n",
    "    \"vmax_925hPa\",\n",
    "    \"vmax_10m\",\n",
    "]\n",
    "huracanpy.load(\n",
    "    huracanpy.example_TRACK_file, source=\"TRACK\", variable_names=variable_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf77611-7b6d-4928-8ba1-b9c7a1602b97",
   "metadata": {},
   "source": [
    "## IBTrACS\n",
    "`huracanpy` includes a subset of the IBTrACS dataset to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c55517-408e-418d-9992-d0a6cf5bde74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ibtracs_subset is \"wmo\" or \"usa\" which correspond to the slp/variables used\n",
    "huracanpy.load(source=\"ibtracs\", ibtracs_subset=\"wmo\", ibtracs_online=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0afeef-3143-4530-ae74-96ef8cdc2707",
   "metadata": {},
   "source": [
    "You can download the full IBTrACS dataset by setting `ibtracs_online=True`. In this case\n",
    "the subset refers to the official IBTrACS subsets.\n",
    "\n",
    "`huracanpy` won't load locally saved copies of IBTrACS. We would recommend downloading\n",
    "once with `ibtracs_online=True` and subsetting then saving a copy as CSV or NetCDF with\n",
    "`ibtracs.save`. Also note that the NetCDF files provided by IBTrACS are not (currently)\n",
    "compatible with `huracanpy` because the format is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a50d3d-cce4-4fc5-8915-61a4a8bfa6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not running this code for the documentation since it downloads the file when run\n",
    "# huracanpy.load(source=\"IBTrACS\", subset=\"ALL\", ibtracs_online=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ccdb6-e2c9-4c54-b1c3-af5b40b68196",
   "metadata": {},
   "source": [
    "## Saving data\n",
    "\n",
    "`huracanpy.save` supports saving data as CSV or NetCDF which is detected by the file\n",
    "extension.\n",
    "\n",
    "You can also use\n",
    "[xarray.Dataset.to_netcdf](https://docs.xarray.dev/en/latest/generated/xarray.Dataset.to_netcdf.html)\n",
    "to save NetCDF files, but they must then be loaded with\n",
    "[xarray.open_dataset](https://docs.xarray.dev/en/latest/generated/xarray.open_dataset.html)\n",
    "`huracanpy.save` does call `to_netcdf` but also has some additional steps to make sure\n",
    "the resulting NetCDF file uses the CF convention used for loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edf32eb-b901-4592-be31-d9227a66c1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = huracanpy.load(huracanpy.example_csv_file)\n",
    "huracanpy.save(tracks, \"saved_data.csv\")\n",
    "huracanpy.save(tracks, \"saved_data.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14512c2-892d-406c-bc76-2c96d6714155",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -5 saved_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee7fcf5-2d1d-4d86-bba1-8c24c0f17cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ncdump -h saved_data.nc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
